{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af48c9c1-44af-4e56-80aa-06b882db53dc",
   "metadata": {},
   "source": [
    "# Read Netcdf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94daeac-e7ff-49f1-aadf-eb81c50d8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from models import DiT_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f9b1f-fb4e-4c9b-88ca-e6f11860cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/p/project1/training2533/patnala1/WeGenDiffusion/data/2011_t2m_era5_2deg.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ff409-3151-4daa-bfed-51220e1f683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0f1d0-50b5-4773-8405-06887718fcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x1509e1778bf0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['t2m'].isel(valid_time=4).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4012aa9-5a1f-44ea-81e8-02a964494961",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"sample_fig.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a57e890-d0c0-4381-8822-2bd8802db2de",
   "metadata": {},
   "source": [
    "# Forward process\n",
    "Iteratively adding Gaussian noise   \n",
    "\n",
    "One step method to emulate multiple timesteps at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e68f78-5dc3-4f1c-b9af-58bf051d4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion import create_diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e092edb-b4a7-4f14-a712-8e56a7aa4f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = create_diffusion(timestep_respacing=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b5a3ca-97f1-4ebe-8a24-afeb085ba29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_map = torch.from_numpy((ds['t2m'].isel(valid_time=4).values - ds.mean()['t2m'].values)/ds.std()['t2m'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d2cf7d-b7da-47c0-a8fe-3ed341ddd389",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for i in range(0, 1000, 50):\n",
    "    timestep = torch.tensor(i, dtype=torch.long).to(sample_map.device)\n",
    "    samples.append(xr.Dataset({\n",
    "    \"t2m\": ((\"lat\", \"lon\"), (diffusion.q_sample(sample_map, timestep) * ds.std()['t2m'].values) + ds.mean()['t2m'].values )\n",
    "    },\n",
    "    coords={\n",
    "        'lat':ds['lat'],\n",
    "         'lon':ds['lon']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d939d-d999-45be-8322-13ddd6167446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, (90, 180))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples),samples[0]['t2m'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0190076f-7272-4ada-a517-ff5bbd608399",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = xr.concat(samples,dim=\"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f47c3a6-86b4-47e0-abe4-4202570dd27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"t2m\"].plot(\n",
    "    col=\"samples\",\n",
    "    col_wrap=5,\n",
    "    cmap=\"viridis\",\n",
    "    cbar_kwargs={\n",
    "        \"orientation\": \"vertical\",   # vertical colorbar at the side\n",
    "        \"pad\": 0.05,                  # distance from the plots\n",
    "        \"shrink\": 0.8                  # shrink length\n",
    "    },\n",
    "    vmin=220,\n",
    "    vmax=320\n",
    ")\n",
    "plt.savefig(\"forward_process.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132df55a-f082-4fa8-8ab2-74c34c8639ea",
   "metadata": {},
   "source": [
    "# Reverse process\n",
    "Remove noise iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd630d9-dc81-4c47-9c7b-c592702a0049",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./results/DiT-B-2_old/ckpt_0000240.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b19a054-3196-492f-b17e-2d5720a292bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = torch.load(model_path, map_location='cuda')['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb206b-b042-4df6-964e-89f5c2d45e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiT_models['DiT-B/2'](input_size=(90,180),num_classes=1000).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205d7e7b-49a4-4f69-9950-e379cb031bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_state_dict,strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71c392-17bf-4a34-81f0-426e2eb676fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiT(\n",
       "  (x_embedder): PatchEmbed(\n",
       "    (proj): Conv2d(1, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (t_embedder): TimestepEmbedder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (y_embedder): LabelEmbedder(\n",
       "    (embedding_table): Embedding(1001, 768)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x DiTBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='tanh')\n",
       "        (drop1): Dropout(p=0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (adaLN_modulation): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=768, out_features=4608, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_layer): FinalLayer(\n",
       "    (norm_final): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "    (linear): Linear(in_features=768, out_features=8, bias=True)\n",
       "    (adaLN_modulation): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1974ec-6ac5-481a-bca5-6b88bab3b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = create_diffusion(timestep_respacing=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cabcb74-e80b-44e6-a9d1-173152be3237",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1,1,90,180)\n",
    "y = torch.zeros_like(torch.Tensor(shape[0]),dtype=torch.long,device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e8a5f-ecca-4d10-9c7c-7a2590e14651",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_images = diffusion.p_sample_loop_progressive(model,shape,model_kwargs=dict(y=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aebfff0-b28b-452f-b741-b098a236cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "xarray_images = []\n",
    "for idx,denoised_image in enumerate(denoised_images):\n",
    "    if (idx+1)%50 == 0:\n",
    "        xarray_images.append(torch.squeeze(denoised_image[\"sample\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1d0354-2a9c-4a7e-b0ec-456f406d4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = ds.mean()['t2m'].values\n",
    "std = ds.std()['t2m'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d52f2-2e90-4f60-8c3c-77d47f69f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for i in range(20):\n",
    "    samples.append(xr.Dataset({\n",
    "    \"t2m\": ((\"lat\", \"lon\"), mean + std*xarray_images[i].cpu().numpy())\n",
    "    },\n",
    "    coords={\n",
    "        'lon':ds['lon'],\n",
    "         'lat':ds['lat']}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa664c-1bb6-4c16-87a7-1488c2ea582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = xr.concat(samples,dim=\"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1b662-1fc9-4a00-ab72-fbc45a24f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"t2m\"].plot(\n",
    "    col=\"samples\",\n",
    "    col_wrap=5,\n",
    "    cmap=\"viridis\",\n",
    "    cbar_kwargs={\n",
    "        \"orientation\": \"vertical\",   # vertical colorbar at the side\n",
    "        \"pad\": 0.05,                  # distance from the plots\n",
    "        \"shrink\": 0.8                  # shrink length\n",
    "    },\n",
    "    vmin=220,\n",
    "    vmax=320\n",
    ")\n",
    "plt.savefig(\"reverse_process.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python mlesm",
   "language": "python",
   "name": "mlesm_hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
